@article{Mohamadi2017ntCardAS,
  title={ntCard: a streaming algorithm for cardinality estimation in genomics data},
  author={Hamid Mohamadi and Hamza Khan and Inanç Birol},
  journal={Bioinformatics},
  year={2017},
  volume={33},
  pages={1324 - 1330},
  url={https://api.semanticscholar.org/CorpusID:3809088}
}

%ena
@article{burgin2023european,
  title={The european nucleotide archive in 2022},
  author={Burgin, Josephine and Ahamed, Alisha and Cummins, Carla and Devraj, Rajkumar and Gueye, Khadim and Gupta, Dipayan and Gupta, Vikas and Haseeb, Muhammad and Ihsan, Maira and Ivanov, Eugene and others},
  journal={Nucleic Acids Research},
  volume={51},
  number={D1},
  pages={D121--D125},
  year={2023},
  publisher={Oxford University Press}
}
@article{metaprofi_2023,
	title = {{MetaProFi}: an ultrafast chunked {Bloom} filter for storing and querying protein and nucleotide sequence data for accurate identification of functionally relevant genetic variants},
	volume = {39},
	issn = {1367-4811},
	shorttitle = {{MetaProFi}},
	doi = {10.1093/bioinformatics/btad101},
	abstract = {MOTIVATION: Bloom filters are a popular data structure that allows rapid searches in large sequence datasets. So far, all tools work with nucleotide sequences; however, protein sequences are conserved over longer evolutionary distances, and only mutations on the protein level may have any functional significance.
RESULTS: We present MetaProFi, a Bloom filter-based tool that, for the first time, offers the functionality to build indexes of amino acid sequences and query them with both amino acid and nucleotide sequences, thus bringing sequence comparison to the biologically relevant protein level. MetaProFi implements additional efficient engineering solutions, such as a shared memory system, chunked data storage and efficient compression. In addition to its conceptual novelty, MetaProFi demonstrates state-of-the-art performance and excellent memory consumption-to-speed ratio when applied to various large datasets.
AVAILABILITY AND IMPLEMENTATION: Source code in Python is available at https://github.com/kalininalab/metaprofi.},
	language = {eng},
	number = {3},
	journal = {Bioinformatics (Oxford, England)},
	author = {Srikakulam, Sanjay K. and Keller, Sebastian and Dabbaghie, Fawaz and Bals, Robert and Kalinina, Olga V.},
	month = mar,
	year = {2023},
	pmid = {36825843},
	pmcid = {PMC9994790},
	keywords = {Algorithms, Base Sequence, Data Compression, Proteins, Software},
	pages = {btad101},
	file = {Full Text:/home/vlevallo/Zotero/storage/F8YWEPNG/Srikakulam et al. - 2023 - MetaProFi an ultrafast chunked Bloom filter for s.pdf:application/pdf},
}

@article{binary_fuse_filter_2022,
	title = {Binary {Fuse} {Filters}: {Fast} and {Smaller} {Than} {Xor} {Filters}},
	volume = {27},
	issn = {1084-6654, 1084-6654},
	shorttitle = {Binary {Fuse} {Filters}},
	url = {http://arxiv.org/abs/2201.01174},
	doi = {10.1145/3510449},
	abstract = {Bloom and cuckoo filters provide fast approximate set membership while using little memory. Engineers use them to avoid expensive disk and network accesses. The recently introduced xor filters can be faster and smaller than Bloom and cuckoo filters. The xor filters are within 23\% of the theoretical lower bound in storage as opposed to 44\% for Bloom filters. Inspired by Dietzfelbinger and Walzer, we build probabilistic filters -- called binary fuse filters -- that are within 13\% of the storage lower bound -- without sacrificing query speed. As an additional benefit, the construction of the new binary fuse filters can be more than twice as fast as the construction of xor filters. By slightly sacrificing query speed, we further reduce storage to within 8\% of the lower bound. We compare the performance against a wide range of competitive alternatives such as Bloom filters, blocked Bloom filters, vector quotient filters, cuckoo filters, and the recent ribbon filters. Our experiments suggest that binary fuse filters are superior to xor filters.},
	urldate = {2023-05-17},
	journal = {ACM Journal of Experimental Algorithmics},
	author = {Graf, Thomas Mueller and Lemire, Daniel},
	month = dec,
	year = {2022},
	note = {arXiv:2201.01174 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms},
	pages = {1--15},
	file = {arXiv Fulltext PDF:/home/vlevallo/Zotero/storage/TFGC2MBV/Graf and Lemire - 2022 - Binary Fuse Filters Fast and Smaller Than Xor Fil.pdf:application/pdf;arXiv.org Snapshot:/home/vlevallo/Zotero/storage/2UTGE9WT/2201.html:text/html},
}

@article{xor_filter_2020,
	title = {Xor {Filters}: {Faster} and {Smaller} {Than} {Bloom} and {Cuckoo} {Filters}},
	volume = {25},
	issn = {1084-6654, 1084-6654},
	shorttitle = {Xor {Filters}},
	url = {http://arxiv.org/abs/1912.08258},
	doi = {10.1145/3376122},
	abstract = {The Bloom filter provides fast approximate set membership while using little memory. Engineers often use these filters to avoid slow operations such as disk or network accesses. As an alternative, a cuckoo filter may need less space than a Bloom filter and it is faster. Chazelle et al. proposed a generalization of the Bloom filter called the Bloomier filter. Dietzfelbinger and Pagh described a variation on the Bloomier filter that can be used effectively for approximate membership queries. It has never been tested empirically, to our knowledge. We review an efficient implementation of their approach, which we call the xor filter. We find that xor filters can be faster than Bloom and cuckoo filters while using less memory. We further show that a more compact version of xor filters (xor+) can use even less space than highly compact alternatives (e.g., Golomb-compressed sequences) while providing speeds competitive with Bloom filters.},
	urldate = {2023-05-17},
	journal = {ACM Journal of Experimental Algorithmics},
	author = {Graf, Thomas Mueller and Lemire, Daniel},
	month = dec,
	year = {2020},
	note = {arXiv:1912.08258 [cs]},
	keywords = {Computer Science - Data Structures and Algorithms},
	pages = {1--16},
	file = {arXiv Fulltext PDF:/home/vlevallo/Zotero/storage/3CW9AEVT/Graf and Lemire - 2020 - Xor Filters Faster and Smaller Than Bloom and Cuc.pdf:application/pdf;arXiv.org Snapshot:/home/vlevallo/Zotero/storage/YGTGIVTH/1912.html:text/html},
}

@misc{fulgor_2023,
	title = {Fulgor: {A} fast and compact k-mer index for large-scale matching and color queries},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
	shorttitle = {Fulgor},
	url = {https://www.biorxiv.org/content/10.1101/2023.05.09.539895v1},
	doi = {10.1101/2023.05.09.539895},
	abstract = {The problem of sequence identification or matching — determining the subset of references from a given collection that are likely to contain a query nucleotide sequence — is relevant for many important tasks in Computational Biology, such as metagenomics and pan-genome analysis. Due to the complex nature of such analyses and the large scale of the reference collections a resource-efficient solution to this problem is of utmost importance. The reference collection should therefore be pre-processed into an index for fast queries. This poses the threefold challenge of designing an index that is efficient to query, has light memory usage, and scales well to large collections.
To solve this problem, we describe how recent advancements in associative, order-preserving, k-mer dictionaries can be combined with a compressed inverted index to implement a fast and compact colored de Bruijn graph data structure. This index takes full advantage of the fact that unitigs in the colored de Bruijn graph are monochromatic (all k-mers in a unitig have the same set of references of origin, or “color”), leveraging the order-preserving property of its dictionary. In fact, k-mers are kept in unitig order by the dictionary, thereby allowing for the encoding of the map from k-mers to their inverted lists in as little as 1 + o(1) bits per unitig. Hence, one inverted list per unitig is stored in the index with almost no space/time overhead. By combining this property with simple but effective compression methods for inverted lists, the index achieves very small space.
We implement these methods in a tool called Fulgor. Compared to Themisto, the prior state of the art, Fulgor indexes a heterogeneous collection of 30,691 bacterial genomes in 3.8× less space, a collection of 150,000 Salmonella enterica genomes in approximately 2 × less space, and is at least twice as fast for color queries.
2012 ACM Subject Classification Applied computing → Bioinformatics},
	language = {en},
	urldate = {2023-05-17},
	publisher = {bioRxiv},
	author = {Fan, Jason and Singh, Noor Pratap and Khan, Jamshed and Pibiri, Giulio Ermanno and Patro, Rob},
	month = may,
	year = {2023},
	note = {Pages: 2023.05.09.539895
Section: New Results},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/DXKDIKJ2/Fan et al. - 2023 - Fulgor A fast and compact k-mer index for large-s.pdf:application/pdf},
}

@inproceedings{cuckoo_2014,
	address = {New York, NY, USA},
	series = {{CoNEXT} '14},
	title = {Cuckoo {Filter}: {Practically} {Better} {Than} {Bloom}},
	isbn = {978-1-4503-3279-8},
	shorttitle = {Cuckoo {Filter}},
	url = {https://dl.acm.org/doi/10.1145/2674005.2674994},
	doi = {10.1145/2674005.2674994},
	abstract = {In many networking systems, Bloom filters are used for high-speed set membership tests. They permit a small fraction of false positive answers with very good space efficiency. However, they do not permit deletion of items from the set, and previous attempts to extend "standard" Bloom filters to support deletion all degrade either space or performance. We propose a new data structure called the cuckoo filter that can replace Bloom filters for approximate set membership tests. Cuckoo filters support adding and removing items dynamically while achieving even higher performance than Bloom filters. For applications that store many items and target moderately low false positive rates, cuckoo filters have lower space overhead than space-optimized Bloom filters. Our experimental results also show that cuckoo filters outperform previous data structures that extend Bloom filters to support deletions substantially in both time and space.},
	urldate = {2023-05-17},
	booktitle = {Proceedings of the 10th {ACM} {International} on {Conference} on emerging {Networking} {Experiments} and {Technologies}},
	publisher = {Association for Computing Machinery},
	author = {Fan, Bin and Andersen, Dave G. and Kaminsky, Michael and Mitzenmacher, Michael D.},
	month = dec,
	year = {2014},
	keywords = {bloom filters, compression, cuckoo hashing},
	pages = {75--88},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/DM7JYRPW/Fan et al. - 2014 - Cuckoo Filter Practically Better Than Bloom.pdf:application/pdf},
}

@misc{fimpera_2023,
	title = {fimpera: drastic improvement of {Approximate} {Membership} {Query} data-structures with counts},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {fimpera},
	url = {https://www.biorxiv.org/content/10.1101/2022.06.27.497694v4},
	doi = {10.1101/2022.06.27.497694},
	abstract = {Motivation High throughput sequencing technologies generate massive amounts of biological sequence datasets as costs fall. One of the current algorithmic challenges for exploiting these data on a global scale consists in providing efficient query engines on these petabyte-scale datasets. Most methods indexing those datasets rely on indexing words of fixed length k, called k-mers. Many applications, such as metagenomics, require the abundance of indexed k-mers as well as their simple presence or absence, but no method scales up to petabyte-scaled datasets. This deficiency is primarily because storing abundance requires explicit storage of the k-mers in order to associate them with their counts. Using counting Approximate Membership Queries (cAMQ) data structures, such as counting Bloom filters, provides a way to index large amounts of k-mers with their abundance, but at the expense of a sensible false positive rate.
Results We propose a novel algorithm, called fimpera, that enables the improvement of any cAMQ performance. Applied to counting Bloom filters, our proposed algorithm reduces the false positive rate by two orders of magnitude and it improves the precision of the reported abundances. Alternatively, fimpera allows for the reduction of the size of a counting Bloom filter by two orders of magnitude while maintaining the same precision. fimpera does not introduce any memory overhead and may even reduces the query time.
Availability https://github.com/lrobidou/fimpera
Supplementary information Supplementary data are available at Bioinformatics online.},
	language = {en},
	urldate = {2023-05-17},
	publisher = {bioRxiv},
	author = {Robidou, Lucas and Peterlongo, Pierre},
	month = apr,
	year = {2023},
	note = {Pages: 2022.06.27.497694
Section: New Results},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/PBBD62UW/Robidou and Peterlongo - 2023 - fimpera drastic improvement of Approximate Member.pdf:application/pdf},
}

@article{kmc_2017,
	title = {{KMC} 3: counting and manipulating k-mer statistics},
	volume = {33},
	issn = {1367-4803},
	shorttitle = {{KMC} 3},
	url = {https://doi.org/10.1093/bioinformatics/btx304},
	doi = {10.1093/bioinformatics/btx304},
	abstract = {Counting all k-mers in a given dataset is a standard procedure in many bioinformatics applications. We introduce KMC3, a significant improvement of the former KMC2 algorithm together with KMC tools for manipulating k-mer databases. Usefulness of the tools is shown on a few real problems.Program is freely available at http://sun.aei.polsl.pl/REFRESH/kmc.Supplementary data are available at Bioinformatics online.},
	number = {17},
	urldate = {2023-05-17},
	journal = {Bioinformatics},
	author = {Kokot, Marek and Długosz, Maciej and Deorowicz, Sebastian},
	month = sep,
	year = {2017},
	pages = {2759--2761},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/Y6VPJVU8/Kokot et al. - 2017 - KMC 3 counting and manipulating k-mer statistics.pdf:application/pdf;Snapshot:/home/vlevallo/Zotero/storage/Z67EJCXC/3796399.html:text/html},
}

@article{kmtricks_2022,
	title = {kmtricks: efficient and flexible construction of {Bloom} filters for large sequencing data collections},
	volume = {2},
	issn = {2635-0041},
	shorttitle = {kmtricks},
	url = {https://doi.org/10.1093/bioadv/vbac029},
	doi = {10.1093/bioadv/vbac029},
	abstract = {When indexing large collections of short-read sequencing data, a common operation that has now been implemented in several tools (Sequence Bloom Trees and variants, BIGSI) is to construct a collection of Bloom filters, one per sample. Each Bloom filter is used to represent a set of k-mers which approximates the desired set of all the non-erroneous k-mers present in the sample. However, this approximation is imperfect, especially in the case of metagenomics data. Erroneous but abundant k-mers are wrongly included, and non-erroneous but low-abundant ones are wrongly discarded. We propose kmtricks, a novel approach for generating Bloom filters from terabase-sized collections of sequencing data. Our main contributions are (i) an efficient method for jointly counting k-mers across multiple samples, including a streamlined Bloom filter construction by directly counting, partitioning and sorting hashes instead of k-mers, which is approximately four times faster than state-of-the-art tools; (ii) a novel technique that takes advantage of joint counting to preserve low-abundant k-mers present in several samples, improving the recovery of non-erroneous k-mers. Our experiments highlight that this technique preserves around 8× more k-mers than the usual yet crude filtering of low-abundance k-mers in a large metagenomics dataset.https://github.com/tlemane/kmtricks.Supplementary data are available at Bioinformatics Advances online.},
	number = {1},
	urldate = {2023-03-17},
	journal = {Bioinformatics Advances},
	author = {Lemane, Téo and Medvedev, Paul and Chikhi, Rayan and Peterlongo, Pierre},
	month = jan,
	year = {2022},
	pages = {vbac029},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/3MINEPIS/Lemane et al. - 2022 - kmtricks efficient and flexible construction of B.pdf:application/pdf;Snapshot:/home/vlevallo/Zotero/storage/CIIHHWG7/6576015.html:text/html},
}

@article{bloom_filter_1970,
	title = {Space/time trade-offs in hash coding with allowable errors},
	volume = {13},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/362686.362692},
	doi = {10.1145/362686.362692},
	abstract = {In this paper trade-offs among certain computational factors in hash coding are analyzed. The paradigm problem considered is that of testing a series of messages one-by-one for membership in a given set of messages. Two new hash-coding methods are examined and compared with a particular conventional hash-coding method. The computational factors considered are the size of the hash area (space), the time required to identify a message as a nonmember of the given set (reject time), and an allowable error frequency. The new methods are intended to reduce the amount of space required to contain the hash-coded information from that associated with conventional methods. The reduction in space is accomplished by exploiting the possibility that a small fraction of errors of commission may be tolerable in some applications, in particular, applications in which a large amount of data is involved and a core resident hash area is consequently not feasible using conventional methods. In such applications, it is envisaged that overall performance could be improved by using a smaller core resident hash area in conjunction with the new methods and, when necessary, by using some secondary and perhaps time-consuming test to “catch” the small fraction of errors associated with the new methods. An example is discussed which illustrates possible areas of application for the new methods. Analysis of the paradigm problem demonstrates that allowing a small number of test messages to be falsely identified as members of the given set will permit a much smaller hash area to be used without increasing reject time.},
	number = {7},
	urldate = {2023-03-17},
	journal = {Communications of the ACM},
	author = {Bloom, Burton H.},
	year = {1970},
	keywords = {hash addressing, hash coding, retrieval efficiency, retrieval trade-offs, scatter storage, searching, storage efficiency, storage layout},
	pages = {422--426},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/QKSQ8VHQ/Bloom - 1970 - Spacetime trade-offs in hash coding with allowabl.pdf:application/pdf},
}

@inproceedings{counting_quotient_filter_2017,
	address = {New York, NY, USA},
	series = {{SIGMOD} '17},
	title = {A {General}-{Purpose} {Counting} {Filter}: {Making} {Every} {Bit} {Count}},
	isbn = {978-1-4503-4197-4},
	shorttitle = {A {General}-{Purpose} {Counting} {Filter}},
	url = {https://dl.acm.org/doi/10.1145/3035918.3035963},
	doi = {10.1145/3035918.3035963},
	abstract = {Approximate Membership Query (AMQ) data structures, such as the Bloom filter, quotient filter, and cuckoo filter, have found numerous applications in databases, storage systems, networks, computational biology, and other domains. However, many applications must work around limitations in the capabilities or performance of current AMQs, making these applications more complex and less performant. For example, many current AMQs cannot delete or count the number of occurrences of each input item, take up large amounts of space, are slow, cannot be resized or merged, or have poor locality of reference and hence perform poorly when stored on SSD or disk. This paper proposes a new general-purpose AMQ, the counting quotient filter (CQF). The CQF supports approximate membership testing and counting the occurrences of items in a data set. This general-purpose AMQ is small and fast, has good locality of reference, scales out of RAM to SSD, and supports deletions, counting (even on skewed data sets), resizing, merging, and highly concurrent access. The paper reports on the structure's performance on both manufactured and application-generated data sets. In our experiments, the CQF performs in-memory inserts and queries up to an order-of magnitude faster than the original quotient filter, several times faster than a Bloom filter, and similarly to the cuckoo filter, even though none of these other data structures support counting. On SSD, the CQF outperforms all structures by a factor of at least 2 because the CQF has good data locality. The CQF achieves these performance gains by restructuring the metadata bits of the quotient filter to obtain fast lookups at high load factors (i.e., even when the data structure is almost full). As a result, the CQF offers good lookup performance even up to a load factor of 95\%. Counting is essentially free in the CQF in the sense that the structure is comparable or more space efficient even than non-counting data structures (e.g., Bloom, quotient, and cuckoo filters). The paper also shows how to speed up CQF operations by using new x86 bit-manipulation instructions introduced in Intel's Haswell line of processors. The restructured metadata transforms many quotient filter metadata operations into rank-and-select bit-vector operations. Thus, our efficient implementations of rank and select may be useful for other rank-and-select-based data structures.},
	urldate = {2023-03-17},
	booktitle = {Proceedings of the 2017 {ACM} {International} {Conference} on {Management} of {Data}},
	publisher = {Association for Computing Machinery},
	author = {Pandey, Prashant and Bender, Michael A. and Johnson, Rob and Patro, Rob},
	year = {2017},
	keywords = {bloom filters and hashing, computational biology, network monitoring, sketching and sampling},
	pages = {775--787},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/R8QVJP5B/Pandey et al. - 2017 - A General-Purpose Counting Filter Making Every Bi.pdf:application/pdf},
}

@article{squeakr_2018,
	title = {Squeakr: an exact and approximate k-mer counting system},
	volume = {34},
	issn = {1367-4803},
	shorttitle = {Squeakr},
	url = {https://doi.org/10.1093/bioinformatics/btx636},
	doi = {10.1093/bioinformatics/btx636},
	abstract = {k-mer-based algorithms have become increasingly popular in the processing of high-throughput sequencing data. These algorithms span the gamut of the analysis pipeline from k-mer counting (e.g. for estimating assembly parameters), to error correction, genome and transcriptome assembly, and even transcript quantification. Yet, these tasks often use very different k-mer representations and data structures. In this article, we show how to build a k-mer-counting and multiset-representation system using the counting quotient filter, a feature-rich approximate membership query data structure. We introduce the k-mer-counting/querying system Squeakr (Simple Quotient filter-based Exact and Approximate Kmer Representation), which is based on the counting quotient filter. This off-the-shelf data structure turns out to be an efficient (approximate or exact) representation for sets or multisets of k-mers.Squeakr takes 2×–4.3× less time than the state-of-the-art to count and perform a random-point-query workload. Squeakr is memory-efficient, consuming 1.5×–4.3× less memory than the state-of-the-art. It offers competitive counting performance. In fact, it is faster for larger k-mers, and answers point queries (i.e. queries for the abundance of a particular k-mer) over an order-of-magnitude faster than other systems. The Squeakr representation of the k-mer multiset turns out to be immediately useful for downstream processing (e.g. de Bruijn graph traversal) because it supports fast queries and dynamic k-mer insertion, deletion, and modification.https://github.com/splatlab/squeakr available under BSD 3-Clause License.Supplementary data are available at Bioinformatics online.},
	number = {4},
	urldate = {2023-03-17},
	journal = {Bioinformatics},
	author = {Pandey, Prashant and Bender, Michael A and Johnson, Rob and Patro, Rob},
	month = feb,
	year = {2018},
	pages = {568--575},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/CEGAPVA7/Pandey et al. - 2018 - Squeakr an exact and approximate k-mer counting s.pdf:application/pdf;Snapshot:/home/vlevallo/Zotero/storage/W5C3IJVC/4386917.html:text/html},
}

@misc{kmindex_2023,
	title = {kmindex and {ORA}: indexing and real-time user-friendly queries in terabytes-sized complex genomic datasets},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	shorttitle = {kmindex and {ORA}},
	url = {https://www.biorxiv.org/content/10.1101/2023.05.31.543043v3},
	doi = {10.1101/2023.05.31.543043},
	abstract = {Public sequencing databases contain vast amounts of biological information, yet they are largely underutilized as one cannot efficiently search them for any sequence of interest. We present kmindex, an innovative approach that can index thousands of highly complex metagenomes and perform sequence searches in a fraction of a second. The construction of the index is an order of magnitude faster than previous methods, while search times are two orders of magnitude faster. With negligible false positive rates below 0.01\%, kmindex outperforms the precision of existing approaches by four orders of magnitude. We demonstrate the scalability of kmindex by successfully indexing 1,393 complex marine seawater metagenome samples from the Tara Oceans project. Additionally, we introduce the publicly accessible web server “Ocean Read Atlas” (ORA) at https://ocean-read-atlas.mio.osupytheas.fr/, which enables real-time queries on the entire Tara Oceans dataset. The open-source kmindex software is available at https://github.com/tlemane/kmindex.},
	language = {en},
	urldate = {2024-01-09},
	publisher = {bioRxiv},
	author = {Lemane, Téo and Lezzoche, Nolan and Lecubin, Julien and Pelletier, Eric and Lescot, Magali and Chikhi, Rayan and Peterlongo, Pierre},
	month = jul,
	year = {2023},
	note = {Pages: 2023.05.31.543043
Section: New Results},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/2C2B552S/Lemane et al. - 2023 - kmindex and ORA indexing and real-time user-frien.pdf:application/pdf},
}

@inproceedings{cobs_2019,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {{COBS}: {A} {Compact} {Bit}-{Sliced} {Signature} {Index}},
	isbn = {978-3-030-32686-9},
	shorttitle = {{COBS}},
	doi = {10.1007/978-3-030-32686-9_21},
	abstract = {We present COBS, a COmpact Bit-sliced Signature index, which is a cross-over between an inverted index and Bloom filters. Our target application is to index k-mers of DNA samples or q-grams from text documents and process approximate pattern matching queries on the corpus with a user-chosen coverage threshold. Query results may contain a number of false positives which decreases exponentially with the query length. We compare COBS to seven other index software packages on 100 000 microbial DNA samples. COBS’ compact but simple data structure outperforms the other indexes in construction time and query performance with Mantis by Pandey et al. in second place. However, unlike Mantis and other previous work, COBS does not need the complete index in RAM and is thus designed to scale to larger document sets.},
	language = {en},
	booktitle = {String {Processing} and {Information} {Retrieval}},
	publisher = {Springer International Publishing},
	author = {Bingmann, Timo and Bradley, Phelim and Gauger, Florian and Iqbal, Zamin},
	editor = {Brisaboa, Nieves R. and Puglisi, Simon J.},
	year = {2019},
	pages = {285--303},
	file = {Submitted Version:/home/vlevallo/Zotero/storage/I2X6L5IX/Bingmann et al. - 2019 - COBS A Compact Bit-Sliced Signature Index.pdf:application/pdf},
}

@article{pac_2023,
	title = {Scalable sequence database search using partitioned aggregated {Bloom} comb trees},
	volume = {39},
	issn = {1367-4811},
	url = {https://doi.org/10.1093/bioinformatics/btad225},
	doi = {10.1093/bioinformatics/btad225},
	abstract = {The Sequence Read Archive public database has reached 45 petabytes of raw sequences and doubles its nucleotide content every 2 years. Although BLAST-like methods can routinely search for a sequence in a small collection of genomes, making searchable immense public resources accessible is beyond the reach of alignment-based strategies. In recent years, abundant literature tackled the task of finding a sequence in extensive sequence collections using k-mer-based strategies. At present, the most scalable methods are approximate membership query data structures that combine the ability to query small signatures or variants while being scalable to collections up to 10 000 eukaryotic samples. Results. Here, we present PAC, a novel approximate membership query data structure for querying collections of sequence datasets. PAC index construction works in a streaming fashion without any disk footprint besides the index itself. It shows a 3–6 fold improvement in construction time compared to other compressed methods for comparable index size. A PAC query can need single random access and be performed in constant time in favorable instances. Using limited computation resources, we built PAC for very large collections. They include 32 000 human RNA-seq samples in 5 days, the entire GenBank bacterial genome collection in a single day for an index size of 3.5 TB. The latter is, to our knowledge, the largest sequence collection ever indexed using an approximate membership query structure. We also showed that PAC’s ability to query 500 000 transcript sequences in less than an hour.PAC’s open-source software is available at https://github.com/Malfoy/PAC.},
	number = {Supplement\_1},
	urldate = {2024-01-09},
	journal = {Bioinformatics},
	author = {Marchet, Camille and Limasset, Antoine},
	month = jun,
	year = {2023},
	pages = {i252--i259},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/VJXEVARD/Marchet and Limasset - 2023 - Scalable sequence database search using partitione.pdf:application/pdf;Snapshot:/home/vlevallo/Zotero/storage/RRSP3RGZ/7210475.html:text/html},
}

@article{ggcat_2023,
	title = {Extremely fast construction and querying of compacted and colored de {Bruijn} graphs with {GGCAT}},
	volume = {33},
	issn = {1088-9051},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10538363/},
	doi = {10.1101/gr.277615.122},
	abstract = {Compacted de Bruijn graphs are one of the most fundamental data structures in computational genomics. Colored compacted de Bruijn graphs are a variant built on a collection of sequences and associate to each k-mer the sequences in which it appears. We present GGCAT, a tool for constructing both types of graphs, based on a new approach merging the k-mer counting step with the unitig construction step, as well as on numerous practical optimizations. For compacted de Bruijn graph construction, GGCAT achieves speed-ups of 3× to 21× compared with the state-of-the-art tool Cuttlefish 2. When constructing the colored variant, GGCAT achieves speed-ups of 5× to 39× compared with the state-of-the-art tool BiFrost. Additionally, GGCAT is up to 480× faster than BiFrost for batch sequence queries on colored graphs.},
	number = {7},
	urldate = {2024-01-09},
	journal = {Genome Research},
	author = {Cracco, Andrea and Tomescu, Alexandru I.},
	month = jul,
	year = {2023},
	pmid = {37253540},
	pmcid = {PMC10538363},
	pages = {1198--1207},
	file = {PubMed Central Full Text PDF:/home/vlevallo/Zotero/storage/IBK5HWMP/Cracco and Tomescu - 2023 - Extremely fast construction and querying of compac.pdf:application/pdf},
}

@article{themisto_2023,
	title = {Themisto: a scalable colored k-mer index for sensitive pseudoalignment against hundreds of thousands of bacterial genomes},
	volume = {39},
	issn = {1367-4811},
	shorttitle = {Themisto},
	url = {https://doi.org/10.1093/bioinformatics/btad233},
	doi = {10.1093/bioinformatics/btad233},
	abstract = {Huge datasets containing whole-genome sequences of bacterial strains are now commonplace and represent a rich and important resource for modern genomic epidemiology and metagenomics. In order to efficiently make use of these datasets, efficient indexing data structures—that are both scalable and provide rapid query throughput—are paramount.Here, we present Themisto, a scalable colored k-mer index designed for large collections of microbial reference genomes, that works for both short and long read data. Themisto indexes 179 thousand Salmonella enterica genomes in 9 h. The resulting index takes 142 gigabytes. In comparison, the best competing tools Metagraph and Bifrost were only able to index 11 000 genomes in the same time. In pseudoalignment, these other tools were either an order of magnitude slower than Themisto, or used an order of magnitude more memory. Themisto also offers superior pseudoalignment quality, achieving a higher recall than previous methods on Nanopore read sets.Themisto is available and documented as a C++ package at https://github.com/algbio/themisto available under the GPLv2 license.},
	number = {Supplement\_1},
	urldate = {2024-01-09},
	journal = {Bioinformatics},
	author = {Alanko, Jarno N and Vuohtoniemi, Jaakko and Mäklin, Tommi and Puglisi, Simon J},
	month = jun,
	year = {2023},
	pages = {i260--i269},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/JPY34R66/Alanko et al. - 2023 - Themisto a scalable colored k-mer index for sensi.pdf:application/pdf},
}

@article{bifrost_2020,
	title = {Bifrost: highly parallel construction and indexing of colored and compacted de {Bruijn} graphs},
	volume = {21},
	issn = {1474-760X},
	shorttitle = {Bifrost},
	url = {https://doi.org/10.1186/s13059-020-02135-8},
	doi = {10.1186/s13059-020-02135-8},
	abstract = {Memory consumption of de Bruijn graphs is often prohibitive. Most de Bruijn graph-based assemblers reduce the complexity by compacting paths into single vertices, but this is challenging as it requires the uncompacted de Bruijn graph to be available in memory. We present a parallel and memory-efficient algorithm enabling the direct construction of the compacted de Bruijn graph without producing the intermediate uncompacted graph. Bifrost features a broad range of functions, such as indexing, editing, and querying the graph, and includes a graph coloring method that maps each k-mer of the graph to the genomes it occurs in.},
	number = {1},
	urldate = {2024-01-09},
	journal = {Genome Biology},
	author = {Holley, Guillaume and Melsted, Páll},
	month = sep,
	year = {2020},
	pages = {249},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/FVEWZN9K/Holley and Melsted - 2020 - Bifrost highly parallel construction and indexing.pdf:application/pdf;Snapshot:/home/vlevallo/Zotero/storage/N4VD359D/s13059-020-02135-8.html:text/html},
}

@misc{pebblescout_2023,
	title = {Indexing and searching petabyte-scale nucleotide resources},
	copyright = {© 2023, Posted by Cold Spring Harbor Laboratory. This article is a US Government work. It is not subject to copyright under 17 USC 105 and is also made available for use under a CC0 license},
	url = {https://www.biorxiv.org/content/10.1101/2023.07.09.547343v1},
	doi = {10.1101/2023.07.09.547343},
	abstract = {Searching vast and rapidly growing sets of nucleotide content in data resources, such as runs in Sequence Read Archive and assemblies for whole genome shotgun sequencing projects in GenBank, is currently impractical in any reasonable amount of time or resources available to most researchers. We present Pebblescout, a tool that navigates such content by providing indexing and search capabilities. Indexing uses dense sampling of the sequences in the resource. Search finds subjects that have short sequence matches to a user query with well-defined guarantees. Reported subjects are ranked using a score that considers the informativeness of the matches. Six databases that index over 3.5 petabases were created and used to illustrate the functionality of Pebblescout. Here we show that Pebblescout provides new research opportunities and a data-driven way for finding relevant subsets of large nucleotide resources for analysis, some of which are missed when relying only on sample metadata or tools using pre-defined reference sequences. For two computationally intensive published studies, we show that Pebblescout rejects a significant number of runs analyzed without changing the conclusions of these studies and finds additional relevant runs. A pilot web service for interactively searching the six databases is freely available at https://pebblescout.ncbi.nlm.nih.gov/},
	language = {en},
	urldate = {2024-01-09},
	publisher = {bioRxiv},
	author = {Shiryev, Sergey A. and Agarwala, Richa},
	month = jul,
	year = {2023},
	note = {Pages: 2023.07.09.547343
Section: New Results},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/L6M27IH2/Shiryev and Agarwala - 2023 - Indexing and searching petabyte-scale nucleotide r.pdf:application/pdf},
}

@misc{quotient_filter_2012,
	title = {Don't {Thrash}: {How} to {Cache} {Your} {Hash} on {Flash}},
	shorttitle = {Don't {Thrash}},
	url = {http://arxiv.org/abs/1208.0290},
	doi = {10.48550/arXiv.1208.0290},
	abstract = {This paper presents new alternatives to the well-known Bloom filter data structure. The Bloom filter, a compact data structure supporting set insertion and membership queries, has found wide application in databases, storage systems, and networks. Because the Bloom filter performs frequent random reads and writes, it is used almost exclusively in RAM, limiting the size of the sets it can represent. This paper first describes the quotient filter, which supports the basic operations of the Bloom filter, achieving roughly comparable performance in terms of space and time, but with better data locality. Operations on the quotient filter require only a small number of contiguous accesses. The quotient filter has other advantages over the Bloom filter: it supports deletions, it can be dynamically resized, and two quotient filters can be efficiently merged. The paper then gives two data structures, the buffered quotient filter and the cascade filter, which exploit the quotient filter advantages and thus serve as SSD-optimized alternatives to the Bloom filter. The cascade filter has better asymptotic I/O performance than the buffered quotient filter, but the buffered quotient filter outperforms the cascade filter on small to medium data sets. Both data structures significantly outperform recently-proposed SSD-optimized Bloom filter variants, such as the elevator Bloom filter, buffered Bloom filter, and forest-structured Bloom filter. In experiments, the cascade filter and buffered quotient filter performed insertions 8.6-11 times faster than the fastest Bloom filter variant and performed lookups 0.94-2.56 times faster.},
	urldate = {2024-01-09},
	publisher = {arXiv},
	author = {Bender, Michael A. and Farach-Colton, Martin and Johnson, Rob and Kraner, Russell and Kuszmaul, Bradley C. and Medjedovic, Dzejla and Montes, Pablo and Shetty, Pradeep and Spillane, Richard P. and Zadok, Erez},
	month = aug,
	year = {2012},
	note = {arXiv:1208.0290 [cs]},
	keywords = {Computer Science - Databases},
	annote = {Comment: VLDB2012},
	file = {arXiv Fulltext PDF:/home/vlevallo/Zotero/storage/NU4CKDWJ/Bender et al. - 2012 - Don't Thrash How to Cache Your Hash on Flash.pdf:application/pdf;arXiv.org Snapshot:/home/vlevallo/Zotero/storage/FEGJB2RL/1208.html:text/html},
}

@article{mash_2016,
	title = {Mash: fast genome and metagenome distance estimation using {MinHash}},
	volume = {17},
	issn = {1474-760X},
	shorttitle = {Mash},
	url = {https://doi.org/10.1186/s13059-016-0997-x},
	doi = {10.1186/s13059-016-0997-x},
	abstract = {Mash extends the MinHash dimensionality-reduction technique to include a pairwise mutation distance and P value significance test, enabling the efficient clustering and search of massive sequence collections. Mash reduces large sequences and sequence sets to small, representative sketches, from which global mutation distances can be rapidly estimated. We demonstrate several use cases, including the clustering of all 54,118 NCBI RefSeq genomes in 33 CPU h; real-time database search using assembled or unassembled Illumina, Pacific Biosciences, and Oxford Nanopore data; and the scalable clustering of hundreds of metagenomic samples by composition. Mash is freely released under a BSD license (https://github.com/marbl/mash).},
	number = {1},
	urldate = {2024-01-09},
	journal = {Genome Biology},
	author = {Ondov, Brian D. and Treangen, Todd J. and Melsted, Páll and Mallonee, Adam B. and Bergman, Nicholas H. and Koren, Sergey and Phillippy, Adam M.},
	month = jun,
	year = {2016},
	keywords = {Alignment, Comparative genomics, Genomic distance, Metagenomics, Nanopore, Sequencing},
	pages = {132},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/KFUA5Y6C/Ondov et al. - 2016 - Mash fast genome and metagenome distance estimati.pdf:application/pdf;Snapshot:/home/vlevallo/Zotero/storage/24NI6UZW/s13059-016-0997-x.html:text/html},
}

@article{dashing_2019,
	title = {Dashing: fast and accurate genomic distances with {HyperLogLog}},
	volume = {20},
	issn = {1474-760X},
	shorttitle = {Dashing},
	url = {https://doi.org/10.1186/s13059-019-1875-0},
	doi = {10.1186/s13059-019-1875-0},
	abstract = {Dashing is a fast and accurate software tool for estimating similarities of genomes or sequencing datasets. It uses the HyperLogLog sketch together with cardinality estimation methods that are specialized for set unions and intersections. Dashing summarizes genomes more rapidly than previous MinHash-based methods while providing greater accuracy across a wide range of input sizes and sketch sizes. It can sketch and calculate pairwise distances for over 87K genomes in 6 minutes. Dashing is open source and available at https://github.com/dnbaker/dashing.},
	number = {1},
	urldate = {2024-01-09},
	journal = {Genome Biology},
	author = {Baker, Daniel N. and Langmead, Ben},
	month = dec,
	year = {2019},
	keywords = {Alignment, Genomic distance, Hyperloglog, Metagenomics, Sequencing, Sketch data structures},
	pages = {265},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/TD5JMWR9/Baker and Langmead - 2019 - Dashing fast and accurate genomic distances with .pdf:application/pdf;Snapshot:/home/vlevallo/Zotero/storage/E9WE3KM9/s13059-019-1875-0.html:text/html},
}

@misc{protocols,
  title = {Experiments details and protocols},
  howpublished = {\url{https://github.com/vicLeva/bqf/wiki/Experiments-details-and-protocol-for-BQF-paper-results}},
}

@article{bigsi_2019,
	title = {Ultrafast search of all deposited bacterial and viral genomic data},
	volume = {37},
	copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
	issn = {1546-1696},
	url = {https://www.nature.com/articles/s41587-018-0010-1},
	doi = {10.1038/s41587-018-0010-1},
	abstract = {Exponentially increasing amounts of unprocessed bacterial and viral genomic sequence data are stored in the global archives. The ability to query these data for sequence search terms would facilitate both basic research and applications such as real-time genomic epidemiology and surveillance. However, this is not possible with current methods. To solve this problem, we combine knowledge of microbial population genomics with computational methods devised for web search to produce a searchable data structure named BItsliced Genomic Signature Index (BIGSI). We indexed the entire global corpus of 447,833 bacterial and viral whole-genome sequence datasets using four orders of magnitude less storage than previous methods. We applied our BIGSI search function to rapidly find resistance genes MCR-1, MCR-2, and MCR-3, determine the host-range of 2,827 plasmids, and quantify antibiotic resistance in archived datasets. Our index can grow incrementally as new (unprocessed or assembled) sequence datasets are deposited and can scale to millions of datasets.},
	language = {en},
	number = {2},
	urldate = {2024-01-22},
	journal = {Nature Biotechnology},
	author = {Bradley, Phelim and den Bakker, Henk C. and Rocha, Eduardo P. C. and McVean, Gil and Iqbal, Zamin},
	month = feb,
	year = {2019},
	note = {Number: 2
Publisher: Nature Publishing Group},
	keywords = {Computational platforms and environments, Data mining, Infectious-disease diagnostics, Microbial genetics, Software},
	pages = {152--159},
	file = {Accepted Version:/home/vlevallo/Zotero/storage/5AY6UK5Y/Bradley et al. - 2019 - Ultrafast search of all deposited bacterial and vi.pdf:application/pdf},
}

@article{xorshift_2003,
	title = {Xorshift {RNGs}},
	volume = {8},
	copyright = {Copyright (c) 2003 George Marsaglia},
	issn = {1548-7660},
	url = {https://doi.org/10.18637/jss.v008.i14},
	doi = {10.18637/jss.v008.i14},
	abstract = {Description of a class of simple, extremely fast random number generators (RNGs) with periods 2k - 1 for k = 32, 64, 96, 128, 160, 192. These RNGs seem to pass tests of randomness very well.},
	language = {en},
	urldate = {2024-01-25},
	journal = {Journal of Statistical Software},
	author = {Marsaglia, George},
	month = jul,
	year = {2003},
	pages = {1--6},
	file = {Marsaglia - 2003 - Xorshift RNGs.pdf:/home/vlevallo/Zotero/storage/CZ2N4GIX/Marsaglia - 2003 - Xorshift RNGs.pdf:application/pdf},
}

@misc{xorshift_64,
  title = {Integer Hash Function},
  howpublished = {\url{https://gist.github.com/lh3/59882d6b96166dfc3d8d}},
  author = {Wang, Thomas},
  month = jan,
  year = {1997},
}

@inproceedings{RahmanMedvedevRECOMB20,
  author    = {Amatur Rahman and Paul Medvedev},
  title     = {Representation of $k$-mer sets using spectrum-preserving string sets},
  booktitle = {Research in Computational Molecular Biology - 24th Annual International Conference, {RECOMB} 2020, Padua, Italy, May 10-13, 2020, Proceedings},
  series    = {Lecture Notes in Computer Science},
  volume    = {12074},
  pages     = {152--168},
  publisher = {Springer},
  year      = {2020}
}

@article{sshash_2023,
	title = {On weighted k-mer dictionaries},
	volume = {18},
	issn = {1748-7188},
	url = {https://doi.org/10.1186/s13015-023-00226-2},
	doi = {10.1186/s13015-023-00226-2},
	abstract = {We consider the problem of representing a set of \$\$k\$\$-mers and their abundance counts, or weights, in compressed space so that assessing membership and retrieving the weight of a \$\$k\$\$-mer is efficient. The representation is called a weighted dictionary of \$\$k\$\$-mers and finds application in numerous tasks in Bioinformatics that usually count \$\$k\$\$-mers as a pre-processing step. In fact, \$\$k\$\$-mer counting tools produce very large outputs that may result in a severe bottleneck for subsequent processing. In this work we extend the recently introduced SSHash dictionary (Pibiri in Bioinformatics 38:185–194, 2022) to also store compactly the weights of the \$\$k\$\$-mers. From a technical perspective, we exploit the order of the \$\$k\$\$-mers represented in SSHash to encode runs of weights, hence allowing much better compression than the empirical entropy of the weights. We study the problem of reducing the number of runs in the weights to improve compression even further and give an optimal algorithm for this problem. Lastly, we corroborate our findings with experiments on real-world datasets and comparison with competitive alternatives. Up to date, SSHash is the only \$\$k\$\$-mer dictionary that is exact, weighted, associative, fast, and small.},
	number = {1},
	urldate = {2024-02-11},
	journal = {Algorithms for Molecular Biology},
	author = {Pibiri, Giulio Ermanno},
	month = jun,
	year = {2023},
	keywords = {Compression, Graphs, Hashing, k-mers, Path cover},
	pages = {3},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/SYZVRRFW/Pibiri - 2023 - On weighted k-mer dictionaries.pdf:application/pdf;Snapshot:/home/vlevallo/Zotero/storage/GTN4YIX7/s13015-023-00226-2.html:text/html},
}

@article{sshash_2022,
	title = {Sparse and skew hashing of {K}-mers},
	volume = {38},
	issn = {1367-4803},
	url = {https://doi.org/10.1093/bioinformatics/btac245},
	doi = {10.1093/bioinformatics/btac245},
	abstract = {A dictionary of k-mers is a data structure that stores a set of n distinct k-mers and supports membership queries. This data structure is at the hearth of many important tasks in computational biology. High-throughput sequencing of DNA can produce very large k-mer sets, in the size of billions of strings—in such cases, the memory consumption and query efficiency of the data structure is a concrete challenge.To tackle this problem, we describe a compressed and associative dictionary for k-mers, that is: a data structure where strings are represented in compact form and each of them is associated to a unique integer identifier in the range [0,n). We show that some statistical properties of k-mer minimizers can be exploited by minimal perfect hashing to substantially improve the space/time trade-off of the dictionary compared to the best-known solutions.https://github.com/jermp/sshash.Supplementary data are available at Bioinformatics online.},
	number = {Supplement\_1},
	urldate = {2024-02-11},
	journal = {Bioinformatics},
	author = {Pibiri, Giulio Ermanno},
	month = jun,
	year = {2022},
	pages = {i185--i194},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/UA9KCLYT/Pibiri - 2022 - Sparse and skew hashing of K-mers.pdf:application/pdf;Snapshot:/home/vlevallo/Zotero/storage/5WDZVRS4/6617506.html:text/html},
}


@inproceedings{pthash_2021,
	address = {New York, NY, USA},
	series = {{SIGIR} '21},
	title = {{PTHash}: {Revisiting} {FCH} {Minimal} {Perfect} {Hashing}},
	isbn = {978-1-4503-8037-9},
	shorttitle = {{PTHash}},
	url = {https://doi.org/10.1145/3404835.3462849},
	doi = {10.1145/3404835.3462849},
	abstract = {Given a set S of n distinct keys, a function f that bijectively maps the keys of S into the range (0,...,n-1) is called a minimal perfect hash function for S. Algorithms that find such functions when n is large and retain constant evaluation time are of practical interest; for instance, search engines and databases typically use minimal perfect hash functions to quickly assign identifiers to static sets of variable-length keys such as strings. The challenge is to design an algorithm which is efficient in three different aspects: time to find f (construction time), time to evaluate f on a key of S (lookup time), and space of representation for f. Several algorithms have been proposed to trade-off between these aspects. In 1992, Fox, Chen, and Heath (FCH) presented an algorithm at SIGIR providing very fast lookup evaluation. However, the approach received little attention because of its large construction time and higher space consumption compared to other subsequent techniques. Almost thirty years later we revisit their framework and present an improved algorithm that scales well to large sets and reduces space consumption altogether, without compromising the lookup time. We conduct an extensive experimental assessment and show that the algorithm finds functions that are competitive in space with state-of-the art techniques and provide 2-4x better lookup time.},
	urldate = {2024-02-11},
	booktitle = {Proceedings of the 44th {International} {ACM} {SIGIR} {Conference} on {Research} and {Development} in {Information} {Retrieval}},
	publisher = {Association for Computing Machinery},
	author = {Pibiri, Giulio Ermanno and Trani, Roberto},
	month = jul,
	year = {2021},
	keywords = {compressed data structures, FCH, minimal perfect hashing, XOR},
	pages = {1339--1348},
	file = {Submitted Version:/home/vlevallo/Zotero/storage/2YA6C2EK/Pibiri and Trani - 2021 - PTHash Revisiting FCH Minimal Perfect Hashing.pdf:application/pdf},
}

@article{minimisers_2004,
	title = {Reducing storage requirements for biological sequence comparison},
	volume = {20},
	issn = {1367-4803},
	doi = {10.1093/bioinformatics/bth408},
	abstract = {MOTIVATION: Comparison of nucleic acid and protein sequences is a fundamental tool of modern bioinformatics. A dominant method of such string matching is the 'seed-and-extend' approach, in which occurrences of short subsequences called 'seeds' are used to search for potentially longer matches in a large database of sequences. Each such potential match is then checked to see if it extends beyond the seed. To be effective, the seed-and-extend approach needs to catalogue seeds from virtually every substring in the database of search strings. Projects such as mammalian genome assemblies and large-scale protein matching, however, have such large sequence databases that the resulting list of seeds cannot be stored in RAM on a single computer. This significantly slows the matching process.
RESULTS: We present a simple and elegant method in which only a small fraction of seeds, called 'minimizers', needs to be stored. Using minimizers can speed up string-matching computations by a large factor while missing only a small fraction of the matches found using all seeds.},
	language = {eng},
	number = {18},
	journal = {Bioinformatics (Oxford, England)},
	author = {Roberts, Michael and Hayes, Wayne and Hunt, Brian R. and Mount, Stephen M. and Yorke, James A.},
	month = dec,
	year = {2004},
	pmid = {15256412},
	keywords = {Algorithms, Databases, Genetic, Information Storage and Retrieval, Numerical Analysis, Computer-Assisted, Sequence Alignment, Sequence Analysis},
	pages = {3363--3369},
	file = {Full Text:/home/vlevallo/Zotero/storage/5GEEYUDE/Roberts et al. - 2004 - Reducing storage requirements for biological seque.pdf:application/pdf},
}

@article{superkmer_2013,
	title = {Memory efficient minimum substring partitioning},
	volume = {6},
	issn = {2150-8097},
	url = {https://dl.acm.org/doi/10.14778/2535569.2448951},
	doi = {10.14778/2535569.2448951},
	abstract = {Massively parallel DNA sequencing technologies are revolutionizing genomics research. Billions of short reads generated at low costs can be assembled for reconstructing the whole genomes. Unfortunately, the large memory footprint of the existing de novo assembly algorithms makes it challenging to get the assembly done for higher eukaryotes like mammals. In this work, we investigate the memory issue of constructing de Bruijn graph, a core task in leading assembly algorithms, which often consumes several hundreds of gigabytes memory for large genomes. We propose a disk-based partition method, called Minimum Substring Partitioning (MSP), to complete the task using less than 10 gigabytes memory, without runtime slowdown. MSP breaks the short reads into multiple small disjoint partitions so that each partition can be loaded into memory, processed individually and later merged with others to form a de Bruijn graph. By leveraging the overlaps among the k-mers (substring of length k), MSP achieves astonishing compression ratio: The total size of partitions is reduced from Θ(kn) to Θ(n), where n is the size of the short read database, and k is the length of a k-mer. Experimental results show that our method can build de Bruijn graphs using a commodity computer for any large-volume sequence dataset.},
	number = {3},
	urldate = {2024-02-11},
	journal = {Proceedings of the VLDB Endowment},
	author = {Li, Yang and Kamousi, Pegah and Han, Fangqiu and Yang, Shengqi and Yan, Xifeng and Suri, Subhash},
	month = jan,
	year = {2013},
	pages = {169--180},
	file = {Full Text PDF:/home/vlevallo/Zotero/storage/UCC2E9MQ/Li et al. - 2013 - Memory efficient minimum substring partitioning.pdf:application/pdf},
}


@article{bcalm_2016,
	title = {Compacting de {Bruijn} graphs from sequencing data quickly and in low memory},
	volume = {32},
	issn = {1367-4811},
	doi = {10.1093/bioinformatics/btw279},
	abstract = {MOTIVATION: As the quantity of data per sequencing experiment increases, the challenges of fragment assembly are becoming increasingly computational. The de Bruijn graph is a widely used data structure in fragment assembly algorithms, used to represent the information from a set of reads. Compaction is an important data reduction step in most de Bruijn graph based algorithms where long simple paths are compacted into single vertices. Compaction has recently become the bottleneck in assembly pipelines, and improving its running time and memory usage is an important problem.
RESULTS: We present an algorithm and a tool bcalm 2 for the compaction of de Bruijn graphs. bcalm 2 is a parallel algorithm that distributes the input based on a minimizer hashing technique, allowing for good balance of memory usage throughout its execution. For human sequencing data, bcalm 2 reduces the computational burden of compacting the de Bruijn graph to roughly an hour and 3 GB of memory. We also applied bcalm 2 to the 22 Gbp loblolly pine and 20 Gbp white spruce sequencing datasets. Compacted graphs were constructed from raw reads in less than 2 days and 40 GB of memory on a single machine. Hence, bcalm 2 is at least an order of magnitude more efficient than other available methods.
AVAILABILITY AND IMPLEMENTATION: Source code of bcalm 2 is freely available at: https://github.com/GATB/bcalm
CONTACT: rayan.chikhi@univ-lille1.fr.},
	language = {eng},
	number = {12},
	journal = {Bioinformatics (Oxford, England)},
	author = {Chikhi, Rayan and Limasset, Antoine and Medvedev, Paul},
	month = jun,
	year = {2016},
	pmid = {27307618},
	pmcid = {PMC4908363},
	keywords = {Algorithms, Humans, Programming Languages, Sequence Analysis, DNA},
	pages = {i201--i208},
	file = {Full Text:/home/vlevallo/Zotero/storage/N63HZ2SA/Chikhi et al. - 2016 - Compacting de Bruijn graphs from sequencing data q.pdf:application/pdf},
}