
\chapter{Perspectives and future work}
\label{sec:perspectives}

\section{On human pangenomics: graphs and beyond}
The result of the analysis I conducted in the first phase of my PhD, presented in chapter \ref{pap:first} serves as basis to understand what are the features, the limitations and the usefulness of the software that is currently used or developed to build pangenome graphs. These are based upon the latest developments in terms of computer science algorithms to provide the best computational performance now possible and represents a huge leap compared to the currently standard software used for genomic analysis.
Here I will present a few considerations and perspectives that stem from this as well as from 2 more years of thoughts and discussions with peers of my doctoral program, my supervisors and other colleagues and experts in the field. \\
As we are possibly at the beginning of a change of paradigm between linear reference sequences and genomics analysis to pangenome references and pangenomics analysis, there are a few things that need to be adressed as soon as possible. \\
\textbf{Reproducibility and stability of computation has to be the main focus of the next years for pangenome reference software developing. \\}
In the case of leading general-purpose pangenome reference building tools, like \pggb and \mcactus, that produce variation graphs, it is of upmost importance that the graph generated from a set of sequences is exactly the same when the same data is fed as input. This means that the heuristics used to generate the variation graph are independent of the ordering of the input sequence and do not contain any stochastic process that might alter the structure of the graph. If a tool can produce two variation graph that can spell the same input genomes but that do not have the same internal order, downstream analysis, like read mapping, loci visualization and other application become biased toward the graph, making it less desirable to genomic analysts that rely on the stability of a linear reference. Current liftover and graph-mapping solutions, in my view, can only be a temporary solution if pangenomics is to be adopted and fully accepted in the genomics and genetics field. \\
\textbf{There should be guarantees or estimates on the overall biological correctness of pangenome graphs. \\} 
While \mcactus omits centromeric variation, \pggb does at the cost of producing more complex graphs. The trade-off is not trivial as gaining on "variation resolution" leads, also, to graphs that are more difficult to interpret, especially as the number of input genomes increases. 
Moreover, De Bruijn Graphs are difficult to untangle and understand already at small case. 
A very useful and interesting future development would be to design a method to evaluate thoroughly the (computational and biological) quality of the pangenomic data structure produced. This tool would be a necessary Quality Contro (QC) step in all custom-pangenome based analysis. For human pangenomics, this would be useful for application where a different reference compared to the HPRC precomputed one is needed, for other cases, like bacterias, virus or fungi, where only specific strains and not the entire species is to be considered.

\textbf{De Bruijn Graph methods need a common color file format or interface to push the development of application-specific tools.}
Mathematically clear, computationally efficient and output-stable de Bruijn Graph methods, like the ones that use colored-compacted \dbgs, won't succeed in being real alternatives of alignment based software to perform pangenomic analysis if there won't be a consensus between the main developers on at least a minimum common interface that let users write tools to exploit the information they contain. Standardized file formats \cite{kff} and interfaces for (colored) queries would help other researchers commit into developing tools for \kmer based approaches, independently of the latest tool in the scene. At the current moment, the landscape is quite diverse and new tool are constantly being developed, discouraging, in my view, the needed investment of resources to develop tools for dbg-based downstream analysis. Writing software for genomics application of \kmer based pangenome representations is crucial to make this representation useful to the end users. As the representation of references is better suited to variation graphs, applications of \kmer based tools could provide added value on genomic studies of specific (sub-)populations.

\textbf{Graphs are not the only \kmer based pangenome representation.}
For this specific use-case, other data structure based on \kmers can be used to extract valuable insights. 
As already described, unitig matrices are a new powerful example of \kmer based data structures that can represent the genetic content of a population and its diversity. 
\kmer matrices \cite{kmtricks} can be seen as a pangenome where rows are the \kmers present in the whole populations and columns are the specific individuals. Then the value in the matrix could be an absence/presence binary value, defining a \emph{de facto} euqivalent representation of a colored \dbg. Unitig matrices then contain the same information of a \ccdbg. \\
In my opinion there is great value in being able to demonstrate equivalence between such representation and to develop tools to change of representation such that, depending on the specific application, each user can decide which is of more interest and not be limited by specific tools building specifically formatted data structures. This is another interesting path forward in the field.

\section{Exploring \kmer data structures for pangenomics}